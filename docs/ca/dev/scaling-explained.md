---
title: Scaling Explained
description: In this article we want to explain how scaling works in Spryker PaaS Production environments. 
last_updated: MAy 23, 2024
template: concept-topic-template
redirect_from:
  - /docs/cloud/dev/spryker-cloud-commerce-os/environment-provisioning.html
---

Production environments, unlike staging environments, are equipped with auto-scaling capabilities. This allows the resources used by the application to dynamically scale up or down based on the current load. Generally speaking, there are two types of scaling. We will be using the analogy of a shop checkout to explain both.
## General info on architecture

Spryker is using EC2 hosts to deploy Docker containers on them. One host generally has multiple containers on it which run Spryker services, such as Yves and BackGW. The containers themselves may only reserve up to the configured amount of CPU and RAM of the host machine. Additional hosts are deployed as needed (up to a configured maximum number of hosts) so that more containers can be placed on them in scaling events.
### Vertical Scaling
In vertical scaling, we are making something “bigger.” In our checkout analogy, we are “deploying” a more experienced sales clerk who has a higher “throughput” and can process more clients. In our PaaS infrastructure, components that currently do not support horizontal auto-scaling are scaled vertically based on alert conditions. This applies to services such as Redis, OpenSearch, RabbitMQ, Jenkins, and RDS. Vertical scaling is also used in the so-called task definitions. This is a configuration that determines how much CPU and RAM is available to Docker containers for our services. As we will discuss below, services such as Yves are also horizontally auto-scaled by deploying more Yves containers. The containers themselves can be vertically scaled by configuring the CPU and RAM they are allowed to reserve on the host.

### Horizontal Scaling:
In horizontal scaling, we are “adding more of the same” to a resource to balance out load across multiple processors. When we think about a checkout in a shop, horizontally scaling the checkout would mean opening another checkout line. We “deploy” another clerk so they can open up another checkout line, and the waiting customers can spread out over the two lines that are now open.

Going back to Spryker PaaS: The infrastructure is set up in a way that provides horizontal autoscaling based on AWS native ECS Service Auto Scaling. Horizontal autoscaling is currently configured for Spryker services Yves, Glue, Backoffice, BackGW, and BackAPI and allows these services to horizontally scale based on load. This is guard-railed by a setting that determines the minimum, desired, and maximum number of members of a service scaling group. A load balancer in front of each service is responsible for distributing load across these services.

The step scaling works like this:
There is an autoscaling configuration that has a service-level CPU threshold configured for a "Scale Up" (often 50%) and "Scale Down" (often 25%) scenario. If the Scale Up threshold is exceeded by a service, more containers of that service are deployed until the maximum number of members of a scaling group is reached. If the load subsides, containers are deprovisioned until the desired amount. Even if there is no load, the container count will never be deprovisioned below the minimum number of scaling group members. There is a lot of logic inside the ECS Auto Scaling feature. [Here](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html) is a good entry article on that topic.
You can test autoscaling relatively easily by applying load to the aforementioned services of your application. The application will automatically scale (possibly visible by "steps" in your monitoring—response time will likely climb until a new container is provisioned, which will make it fall again, etc.). You should also be able to see new containers being deployed when checking the ECS overview of the service you are load testing.
As autoscaling is guard-railed by a maximum number of scaling group members, we recommend load and performance testing before going live so that this maximum number can be dialed in more easily. While our monitoring team can adjust these settings on the fly as well, it is normally best to apply a realistic load to the application (containing the data you want to use in production) before going live. This will also help adjust the container CPU and memory budget—which will determine how much CPU and memory each service will "get" compared to other containers. This helps to further optimize the setup.

### Additional notes
You might wonder why there is an upper limit for both host and container counts. While this is also to protect Spryker from excessive costs caused by DDOS attacks and similar threats, it is also to protect connected infrastructure components from being affected by load spikes. We do not want our infrastructure to become part of a chain that allows a load-based attack to reach customer infrastructure.
To dial in appropriate max levels, a load test prior to going live is mission critical. In this load test, you help to establish expected (normal) load as well as peak load for your environment. After that, a buffer is applied, and the max numbers for containers and hosts will be set. Our monitoring team is alerted if your application sees continuous high load that indicates the configured maximum is not enough and can increase the limits on the fly.
Load testing is crucial for another reason: horizontal scaling does not happen in real-time and sets in with a delay. It can take some minutes for new containers to be deployed, especially if that means a new EC2 host needs to be deployed onto which new containers can be placed. Scaling events are, therefore, only a tool to catch variances in load in a delayed manner. By load testing your application, the task definitions of your services can be adjusted so that services that are bottlenecking your applications are assigned more resource budget from the get-go. This will result in fewer autoscaling events as the bottleneck can deal with more traffic before scaling needs to happen. Variances in your load will therefore lead to less “corrective action,” which makes for a more consistent and smoother experience during peak load.
Generally, “spiky” load profiles should be avoided where possible. Marketing activities, such as mass emails with direct links to offers, often lead to immense load spikes. Not only because many users might click the link (this will likely happen not exactly at the same time in problematic quantity), but because many email providers open links contained in email messages to do security checks on them. Depending on the scale of your campaign, this can lead to serious spikes in your application. Staggering campaigns (even if you are only reducing the number of emails sent per second) can already help even out the load and allow the application to scale out.

## Conclusion
Spryker PaaS uses a sophisticated scaling strategy that leads to a performant and smooth experience for your users. This strategy only works after load testing, which should be a mandatory task in your go-live journey and should be repeated when you adjust the application in meaningful ways.
